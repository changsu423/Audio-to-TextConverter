import streamlit as st
import tempfile
import os
import time
from datetime import datetime
import json
import base64
from io import BytesIO
import numpy as np
from pathlib import Path

# Initialize session state variables
if 'recordings' not in st.session_state:
    st.session_state.recordings = []
if 'selected_recording_index' not in st.session_state:
    st.session_state.selected_recording_index = None
if 'is_converting' not in st.session_state:
    st.session_state.is_converting = False
if 'is_recording' not in st.session_state:
    st.session_state.is_recording = False
if 'temp_audio_path' not in st.session_state:
    st.session_state.temp_audio_path = None

# Helper functions for file operations
def load_recordings():
    """Load recordings from a JSON file if it exists."""
    recordings_file = Path("recordings.json")
    if recordings_file.exists():
        with open(recordings_file, "r", encoding="utf-8") as f:
            try:
                # Load recordings but recreate audiodata from Base64
                recordings_data = json.load(f)
                for recording in recordings_data:
                    if 'audio_base64' in recording and recording['audio_base64']:
                        recording['audiodata'] = base64.b64decode(recording['audio_base64'])
                    else:
                        recording['audiodata'] = None
                return recordings_data
            except json.JSONDecodeError:
                return []
    return []

def save_recordings(recordings):
    """Save recordings to a JSON file."""
    recordings_data = []
    for recording in recordings:
        # Make a copy of the recording without the audiodata
        rec_copy = recording.copy()
        # Convert audiodata to Base64 for storage
        if 'audiodata' in rec_copy and rec_copy['audiodata']:
            rec_copy['audio_base64'] = base64.b64encode(rec_copy['audiodata']).decode('utf-8')
        else:
            rec_copy['audio_base64'] = None
        # Remove the binary data
        if 'audiodata' in rec_copy:
            del rec_copy['audiodata']
        recordings_data.append(rec_copy)
        
    with open("recordings.json", "w", encoding="utf-8") as f:
        json.dump(recordings_data, f, ensure_ascii=False, indent=2)

def get_audio_download_link(audio_bytes, filename="recording.wav"):
    """Generate a download link for audio file."""
    b64 = base64.b64encode(audio_bytes).decode()
    href = f'<a href="data:audio/wav;base64,{b64}" download="{filename}">Download Audio</a>'
    return href

def get_text_download_link(text, filename="transcript.txt"):
    """Generate a download link for text file."""
    b64 = base64.b64encode(text.encode()).decode()
    href = f'<a href="data:text/plain;base64,{b64}" download="{filename}">Download Transcript</a>'
    return href

def simulate_transcription(audio_bytes):
    """Simulate audio transcription (in a real app, you would call an STT API here)."""
    # In a real implementation, you would send the audio to a Speech-to-Text service
    # For demo purposes, we'll just wait and return sample text
    progress_bar = st.progress(0)
    for i in range(100):
        time.sleep(0.03)  # Simulate processing time
        progress_bar.progress(i + 1)
    
    # Sample Korean transcript (similar to the React app's demo text)
    transcript = (
        "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ìˆ˜ì—…ì—ì„œëŠ” ì£¼ìš” ê°œë…ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤. "
        "ì²« ë²ˆì§¸ë¡œ ì¤‘ìš”í•œ ì ì€ ë°ì´í„°ì˜ êµ¬ì¡°í™”ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ë©´ "
        "ë¶„ì„ì´ ìš©ì´í•´ì§€ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ê¸° ì‰¬ì›Œì§‘ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” ì•Œê³ ë¦¬ì¦˜ì˜ ì„ íƒì¸ë°, "
        "ë¬¸ì œì— ë”°ë¼ ì ì ˆí•œ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ê²°ê³¼ì˜ ì‹œê°í™”ë¥¼ "
        "í†µí•´ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ ìˆìœ¼ì‹ ê°€ìš”?"
    )
    return transcript

# Load recordings at startup
if not st.session_state.recordings:
    st.session_state.recordings = load_recordings()

# App title and description
st.title("ğŸ™ï¸ ìˆ˜ì—… ë…¹ìŒ ë° í…ìŠ¤íŠ¸ ë³€í™˜ ì•±")
st.write("ìˆ˜ì—…ì„ ë…¹ìŒí•˜ê³  ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì„¸ìš”.")

# Create tabs
tab1, tab2, tab3 = st.tabs(["ë…¹ìŒ", "ë…¹ìŒ ëª©ë¡", "ìƒì„¸ ë³´ê¸°"])

# Tab 1: Recording
with tab1:
    st.subheader("ìˆ˜ì—… ë…¹ìŒ")
    
    # Recording status indicator
    if st.session_state.is_recording:
        st.markdown("### ğŸ”´ ë…¹ìŒ ì¤‘...")
    
    # Recording buttons
    col1, col2 = st.columns(2)
    with col1:
        if not st.session_state.is_recording:
            if st.button("ğŸ¤ ë…¹ìŒ ì‹œì‘", use_container_width=True):
                st.session_state.is_recording = True
                # Use streamlit-webrtc in a real implementation
                # For this demo, we'll simulate recording
                st.session_state.temp_audio_path = tempfile.NamedTemporaryFile(delete=False, suffix='.wav').name
                st.experimental_rerun()
        else:
            if st.button("â¹ï¸ ë…¹ìŒ ì¤‘ì§€ ë° ì €ì¥", use_container_width=True):
                st.session_state.is_recording = False
                
                # In a real implementation, we would save the actual recorded audio
                # For this demo, we'll use a sample audio file or placeholder
                
                # Create a new recording entry
                new_recording = {
                    "id": int(time.time() * 1000),
                    "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "title": f"ë…¹ìŒ {len(st.session_state.recordings) + 1}",
                    "audiodata": open("sample.wav", "rb").read() if Path("sample.wav").exists() else b"PLACEHOLDER",
                    "duration": 15,  # Placeholder duration in seconds
                    "transcript": None
                }
                
                # Add to recordings and save
                st.session_state.recordings.insert(0, new_recording)
                save_recordings(st.session_state.recordings)
                
                # Automatically select the new recording
                st.session_state.selected_recording_index = 0
                
                st.experimental_rerun()
    
    # Display recording instructions
    st.markdown("---")
    st.info("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•˜ê³  ë…¹ìŒ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìˆ˜ì—…ì„ ë…¹ìŒí•˜ì„¸ìš”. ë…¹ìŒì´ ëë‚˜ë©´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # Recently recorded audio (if any)
    if st.session_state.selected_recording_index is not None and st.session_state.selected_recording_index == 0:
        recent_recording = st.session_state.recordings[0]
        st.subheader("ë°©ê¸ˆ ë…¹ìŒë¨:")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("â–¶ï¸ ì¬ìƒ", use_container_width=True):
                # In a real app, we would play the audio
                st.audio(recent_recording["audiodata"], format="audio/wav")
        
        with col2:
            if not recent_recording["transcript"] and not st.session_state.is_converting:
                if st.button("ğŸ”„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜", use_container_width=True):
                    st.session_state.is_converting = True
                    st.experimental_rerun()

# Tab 2: Recording List
with tab2:
    st.subheader("ğŸ—‚ï¸ ë…¹ìŒ ëª©ë¡")
    
    if not st.session_state.recordings:
        st.info("ë…¹ìŒ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for i, recording in enumerate(st.session_state.recordings):
            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    title = recording["title"]
                    date = recording["date"]
                    duration = f"{recording['duration']}ì´ˆ" if 'duration' in recording else ""
                    has_transcript = "âœ… í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ" if recording.get("transcript") else ""
                    
                    if st.button(f"**{title}**\n{date} | {duration} {has_transcript}", key=f"rec_{i}", use_container_width=True):
                        st.session_state.selected_recording_index = i
                        st.experimental_rerun()
                
                with col2:
                    st.audio(recording["audiodata"], format="audio/wav")

# Tab 3: Detailed View
with tab3:
    if st.session_state.selected_recording_index is not None:
        recording = st.session_state.recordings[st.session_state.selected_recording_index]
        
        # Header with recording info
        st.subheader(f"ğŸ“„ {recording['title']}")
        st.caption(f"ë…¹ìŒì¼: {recording['date']} | ê¸¸ì´: {recording.get('duration', '?')}ì´ˆ")
        
        # Audio playback
        st.audio(recording["audiodata"], format="audio/wav")
        
        # Audio download button
        st.markdown(get_audio_download_link(recording["audiodata"], f"{recording['title']}.wav"), unsafe_allow_html=True)
        
        # Transcription section
        st.markdown("---")
        st.subheader("í…ìŠ¤íŠ¸ ë³€í™˜")
        
        if st.session_state.is_converting and recording.get("transcript") is None:
            st.info("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘...")
            transcript = simulate_transcription(recording["audiodata"])
            
            # Update recording with transcript
            recording["transcript"] = transcript
            st.session_state.recordings[st.session_state.selected_recording_index] = recording
            save_recordings(st.session_state.recordings)
            
            st.session_state.is_converting = False
            st.experimental_rerun()
            
        elif recording.get("transcript"):
            # Display transcript
            st.text_area("ë³€í™˜ëœ í…ìŠ¤íŠ¸:", value=recording["transcript"], height=200, disabled=True)
            
            # Text download button
            st.markdown(get_text_download_link(recording["transcript"], f"{recording['title']}-í…ìŠ¤íŠ¸ë³€í™˜.txt"), unsafe_allow_html=True)
        else:
            st.info("ì•„ì§ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            if st.button("ğŸ”„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"):
                st.session_state.is_converting = True
                st.experimental_rerun()
        
        # Edit and delete options
        st.markdown("---")
        col1, col2 = st.columns(2)
        
        with col1:
            new_title = st.text_input("ì œëª© ìˆ˜ì •:", value=recording["title"])
            if new_title != recording["title"]:
                if st.button("ì œëª© ì €ì¥"):
                    recording["title"] = new_title
                    st.session_state.recordings[st.session_state.selected_recording_index] = recording
                    save_recordings(st.session_state.recordings)
                    st.success("ì œëª©ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        with col2:
            if st.button("ğŸ—‘ï¸ ë…¹ìŒ ì‚­ì œ", use_container_width=True):
                if st.session_state.recordings:
                    st.session_state.recordings.pop(st.session_state.selected_recording_index)
                    save_recordings(st.session_state.recordings)
                    st.session_state.selected_recording_index = None
                    st.success("ë…¹ìŒì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.experimental_rerun()
    else:
        st.info("ë…¹ìŒì„ ì„ íƒí•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
